# Playing with stable diffusion

## What I had in mind before the trial

My objective was to be able to locally create an <b>ai generated drawing.</b>
This drawing would illustrate my first blog post.
As a result, the prompt I had in mind was:
<p style='text-align: center;'><i>Somebody writing his first blog post on github</i></p>
Obviously, the idea is that the drawing would match the prompt description.
Let's see how I have done it!

## The making of

### Getting the model: The Huggingface hub
First thing first, I went to huggingface to get the model. You need to log in (or create an account) and agree to the stable diffusion model license. 
<br>You can follow the link:
<br>[HuggingFace stable diffusion model](https://huggingface.co/CompVis/stable-diffusion-v1-4)

### terminal operations

pip install --upgrade diffusers transformers scipy
huggingface-cli login
git config --global credential.helper store

### Jupyter notebook

import torch
from torch import autocast
from diffusers import StableDiffusionPipeline

model_id = "CompVis/stable-diffusion-v1-4"
device = "cuda"


pipe = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token=True)
pipe = pipe.to(device)

prompt = "Somebody writing his first blog post on github"
with autocast("cuda"):
    image = pipe(prompt, guidance_scale=7.5).images[0]  
    
image.save("first_blog_post_ai_generated_drawing.png")

Download 16 files and several Gbs later...

## Getting an error

<i>AssertionError: Torch not compiled with CUDA enabled</i>

It turned out I didn't install correctly PyTorch when I followed this link to debug it:

[github issue](https://github.com/pytorch/pytorch/issues/30664)
<br><br>solution:
<br>pip3 install torch torchvision torchaudio


## The result

